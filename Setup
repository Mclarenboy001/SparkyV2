# 🚀 Sparky - Complete Setup Tutorial

## 📋 Table of Contents
1. [System Requirements Check](#system-requirements-check)
2. [Python Installation](#python-installation)
3. [GPU Setup (Optional but Recommended)](#gpu-setup-optional-but-recommended)
4. [Dependencies Installation](#dependencies-installation)
5. [Application Setup](#application-setup)
6. [First Run & Testing](#first-run--testing)
7. [Troubleshooting](#troubleshooting)
8. [Performance Optimization](#performance-optimization)

---

## 🔍 System Requirements Check

### Step 1: Check Your Hardware

**Windows Users:**
```
1. Press Windows Key + R
2. Type "dxdiag" and press Enter
3. Check "System" tab for RAM and CPU
4. Check "Display" tab for GPU information
```

**Check GPU VRAM:**
```
1. Open Task Manager (Ctrl + Shift + Esc)
2. Go to "Performance" tab
3. Click "GPU 0" on the left
4. Look for "Dedicated GPU memory"
```

**Minimum Requirements Checklist:**
- [ ] CPU: Intel i3-4000+ / AMD Ryzen 3+
- [ ] RAM: 4GB (8GB recommended)
- [ ] Storage: 8GB free space
- [ ] GPU: GTX 1060 6GB+ (for GPU mode)
- [ ] VRAM: 6GB+ (for GPU acceleration)

---

## 🐍 Python Installation

### Step 1: Download Python

**Windows:**
```
1. Go to https://python.org/downloads
2. Download Python 3.10 or 3.11 (recommended)
3. ⚠️ IMPORTANT: Check "Add Python to PATH" during installation
4. Choose "Install for all users" if you have admin rights
```

**macOS:**
```
1. Go to https://python.org/downloads
2. Download Python 3.10+ for macOS
3. Install the .pkg file
```

**Linux (Ubuntu/Debian):**
```bash
sudo apt update
sudo apt install python3.10 python3-pip python3-venv
```

### Step 2: Verify Python Installation

Open Command Prompt/Terminal and run:
```bash
python --version
# Should show: Python 3.10.x or 3.11.x

pip --version
# Should show pip version information
```

**If "python" doesn't work, try:**
```bash
python3 --version
pip3 --version
```

---

## 🚀 GPU Setup (Optional but Recommended)

### Step 1: Check GPU Compatibility

**NVIDIA GPU Required for GPU acceleration**

**Check CUDA Compatibility:**
```
1. Go to https://developer.nvidia.com/cuda-gpus
2. Find your GPU model
3. Check "Compute Capability" (need 6.1+)
```

**Supported GPUs:**
- ✅ RTX 4090, 4080, 4070, 4060
- ✅ RTX 3090, 3080, 3070, 3060  
- ✅ RTX 2080, 2070, 2060
- ✅ GTX 1660 Ti, 1080 Ti, 1070, 1060 6GB
- ❌ AMD GPUs (not supported)
- ❌ GTX 1050/1030 (insufficient VRAM)

### Step 2: Install NVIDIA Drivers

**Windows:**
```
1. Go to https://geforce.com/drivers
2. Auto-detect your GPU or search manually
3. Download and install latest Game Ready Driver
4. Restart computer after installation
```

**Verify Driver Installation:**
```
1. Open Command Prompt
2. Run: nvidia-smi
3. Should show GPU information and driver version
```

### Step 3: Install CUDA Toolkit (Advanced Users)

**For most users, skip this step - PyTorch will handle CUDA**

**If you want full CUDA toolkit:**
```
1. Go to https://developer.nvidia.com/cuda-downloads
2. Select your OS and architecture
3. Download CUDA 11.8 or 12.x
4. Install with default settings
```

---

## 📦 Dependencies Installation

### Step 1: Create Virtual Environment (Recommended)

**Create isolated environment:**
```bash
# Navigate to where you want the project
cd Desktop
mkdir ScreenAnswer
cd ScreenAnswer

# Create virtual environment
python -m venv screen_answer_env

# Activate environment
# Windows:
screen_answer_env\Scripts\activate
# macOS/Linux:
source screen_answer_env/bin/activate
```

**You should see (screen_answer_env) in your command prompt**

### Step 2: Install PyTorch with CUDA Support

**For GPU Users (NVIDIA):**
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

**For CPU-Only Users:**
```bash
pip install torch torchvision torchaudio
```

**Verify PyTorch Installation:**
```bash
python -c "import torch; print('CUDA Available:', torch.cuda.is_available()); print('GPU Name:', torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None')"
```

### Step 3: Install Core Dependencies

**Install all required packages:**
```bash
pip install pillow pyautogui opencv-python numpy easyocr gpt4all psutil tkinter
```

**For better performance, also install:**
```bash
pip install opencv-contrib-python
```

### Step 4: Verify Installation

**Test all imports:**
```bash
python -c "import torch, easyocr, gpt4all, PIL, pyautogui, cv2, numpy; print('✅ All packages installed successfully!')"
```

---

## 💻 Application Setup

### Step 1: Download the Application

**Save the Python script:**
```
1. Copy the complete Python code from the artifact
2. Save as "gpu_screen_answer.py"
3. Place in your ScreenAnswer folder
```

### Step 2: Make Script Executable

**Windows:**
```
Right-click gpu_screen_answer.py → "Open with" → Python
```

**macOS/Linux:**
```bash
chmod +x gpu_screen_answer.py
```

### Step 3: Create Desktop Shortcut (Optional)

**Windows:**
```
1. Right-click on Desktop → New → Shortcut
2. Browse to your gpu_screen_answer.py file
3. Name it "GPU Screen Answer"
4. Edit shortcut properties to start in correct folder
```

---

## 🎯 First Run & Testing

### Step 1: Launch Application

**From command line:**
```bash
# Make sure virtual environment is activated
cd ScreenAnswer
python gpu_screen_answer.py
```

### Step 2: Initialization Process

**What you'll see:**
```
1. "Initializing GPU components..." (blue text)
2. GPU detection and driver check
3. "Loading OCR reader..." 
4. "Loading AI model..." (this takes 2-5 minutes first time)
5. Model downloads automatically (4-8GB)
6. "✅ Ready!" (green text)
```

**First run timeline:**
- GPU Detection: 5 seconds
- OCR Loading: 30 seconds  
- AI Model Download: 5-15 minutes (one time only)
- AI Model Loading: 1-3 minutes
- **Total first run**: 10-20 minutes

### Step 3: Test Basic Functionality

**Test 1: Screen Capture**
```
1. Click "📸 GPU Capture" (or "📸 Capture" for CPU)
2. Should see screenshot in the black canvas area
3. Status should show "✅ Image captured!"
```

**Test 2: OCR Test**
```
1. Open a webpage with text
2. Click "🚀 GPU Answer" button
3. Wait 2 seconds for capture delay
4. Should see extracted text in the response area
```

**Test 3: AI Response**
```
1. Capture an image with a question
2. Watch the live streaming response
3. Check performance stats at bottom right
```

### Step 4: Check GPU Acceleration

**Verify GPU is working:**
```
1. Menu → GPU → GPU Information
2. Should show your GPU name and memory
3. Status should show "🚀 GPU: [Your GPU Name]"
4. Performance should be much faster than CPU
```

---

## 🔧 Troubleshooting

### Common Issues & Solutions

#### "CUDA not available" Error
```
Problem: GPU not detected
Solutions:
1. Update NVIDIA drivers
2. Reinstall PyTorch with CUDA:
   pip uninstall torch torchvision torchaudio
   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
3. Check GPU compatibility (need 6GB+ VRAM)
4. Use CPU mode instead
```

#### "ModuleNotFoundError" 
```
Problem: Missing dependencies
Solutions:
1. Activate virtual environment first
2. Install missing package:
   pip install [package_name]
3. Reinstall all dependencies:
   pip install -r requirements.txt
```

#### "Out of Memory" Error
```
Problem: Insufficient GPU VRAM
Solutions:
1. Close other GPU-intensive programs
2. Switch to smaller AI model in settings
3. Use CPU mode instead
4. Reduce batch size in code
```

#### Slow Performance on GPU
```
Problem: Not using GPU acceleration
Check:
1. GPU menu → GPU Information
2. Should show CUDA Available: ✅ Yes
3. Current Mode should be "🚀 GPU"
4. Performance stats should show GPU times

Solutions:
1. Settings → Toggle GPU/CPU Mode
2. Restart application
3. Update GPU drivers
```

#### Model Download Fails
```
Problem: Network or storage issues
Solutions:
1. Check internet connection
2. Ensure 8GB+ free disk space
3. Try different model in Settings menu
4. Manual download from GPT4All website
```

#### Application Won't Start
```
Problem: Python environment issues
Solutions:
1. Check Python version: python --version
2. Reinstall in clean virtual environment
3. Run as administrator (Windows)
4. Check file permissions (macOS/Linux)
```

### Performance Issues

#### Slow OCR (>5 seconds)
```
Likely causes:
1. Using CPU instead of GPU
2. Large image size
3. Complex image content

Solutions:
1. Enable GPU mode
2. Set capture region instead of full screen
3. Use simpler images for testing
```

#### Slow AI Responses (>60 seconds)
```
Likely causes:
1. Large AI model on insufficient hardware
2. CPU mode instead of GPU
3. Insufficient RAM

Solutions:
1. Switch to smaller model (Orca Mini 3B)
2. Enable GPU acceleration
3. Close other applications
4. Add more RAM
```

### Getting Help

#### Debug Information
```
1. Click "🔧 Debug" button in application
2. Check desktop for debug file
3. Include GPU information from GPU menu
4. Note exact error messages
```

#### Log Files Location
```
Windows: Desktop\GPU_ScreenAnswer_Debug.txt
macOS: ~/Desktop/GPU_ScreenAnswer_Debug.txt  
Linux: ~/Desktop/GPU_ScreenAnswer_Debug.txt
```

---

## ⚡ Performance Optimization

### GPU Optimization

#### For RTX 4090/4080 (High-end)
```
Settings:
✅ Use largest models (WizardLM 13B)
✅ Keep GPU mode always on
✅ Enable all GPU features
Expected performance: <5 second responses
```

#### For RTX 3060/2060 (Mid-range)
```
Settings:
✅ Use Llama 3 8B or Mistral 7B
✅ GPU mode for most tasks
✅ Switch to CPU for very long texts
Expected performance: 8-15 second responses
```

#### For GTX 1060 6GB (Entry-level)
```
Settings:
⚠️ Use Llama 3 8B (may be slow)
⚠️ Switch between GPU/CPU as needed
⚠️ Close other GPU applications
Expected performance: 15-30 second responses
```

### CPU Optimization (No GPU)

#### For Intel i7/AMD Ryzen 7+
```
Settings:
✅ Use Llama 3 8B model
✅ Close unnecessary programs
✅ Use capture regions instead of full screen
Expected performance: 45-90 second responses
```

#### For Intel i5/AMD Ryzen 5
```
Settings:
⚠️ Use Orca Mini 3B (faster)
⚠️ Limit multitasking
⚠️ Use for simple questions only
Expected performance: 60-120 second responses
```

### Memory Optimization

#### RAM Usage Tips
```
✅ Close web browsers with many tabs
✅ Exit other AI/ML applications
✅ Use Task Manager to monitor memory
✅ Consider upgrading to 16GB+ for best experience
```

#### GPU Memory Tips
```
✅ Monitor GPU memory in Task Manager
✅ Close games and 3D applications
✅ Restart application if memory issues persist
✅ Use smaller models if out of VRAM
```

---

## ✅ Quick Start Checklist

### Before First Run:
- [ ] Python 3.10/3.11 installed with PATH
- [ ] Virtual environment created and activated
- [ ] PyTorch installed with CUDA support (GPU users)
- [ ] All dependencies installed successfully
- [ ] NVIDIA drivers updated (GPU users)
- [ ] 8GB+ free disk space for AI models
- [ ] Stable internet connection for model download

### After Installation:
- [ ] Application starts without errors
- [ ] GPU detected (if available) 
- [ ] Screen capture works
- [ ] OCR extracts text correctly
- [ ] AI generates responses
- [ ] Performance stats show reasonable times
- [ ] Debug information accessible

### Ready to Use! 🎉

You now have a powerful AI-powered screen analysis tool that can:
- 📸 Capture any part of your screen
- 🔍 Extract text with GPU-accelerated OCR
- 🤖 Answer questions using advanced AI models
- ⚡ Process everything locally with no internet required
- 🚀 Run at blazing speeds with GPU acceleration

**Enjoy your new AI HW solver!** 🎯
